{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning about Rate Limiting\n",
    "Lightspeed limits the rate at which you can get data in two ways:\n",
    "    1. It limits the number of records returned to 100\n",
    "    2. It limits the frequency that you can request data using a \"leaky-bucket\" algorythm\n",
    "In order to get large amounts of data out, you need to deal with both of these. you can [read Lightspeeds doc here](https://developers.lightspeedhq.com/retail/introduction/ratelimits/). This example was written as I was trying to learn about how it works, and how to deal with it. It is included here in case you need to walk through it to0. However, most of this logic will me moved to the pyLightspeed.retail module so you probably don't need to worry about it. "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get set up\n",
    "We are going to use the pyLightspeed retail module, as well as some others that we will need included. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "print(sys.path)\n",
    "from retail.retail import connection\n",
    "\n",
    "import logging\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Start logging\n",
    "logging.basicConfig(level=logging.DEBUG, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logging.debug('Start of program')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establish a Connection\n",
    "Best practice would be to store your keys as environment variables, but I have set the connection object up to take both a file and environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY_FILE = \"D:\\Development\\.keys\\lightspeed_keys.json\"\n",
    "\n",
    "with open(KEY_FILE) as f:\n",
    "    keys = json.load(f)\n",
    "\n",
    "store_data = {\n",
    "            'account_id': keys[\"account_id\"],\n",
    "            'save_path': 'D:\\\\Development\\\\.keys\\\\'\n",
    "            }\n",
    "\n",
    "credentials = {\n",
    "            'client_id': keys[\"client_id\"],\n",
    "            'client_secret': keys[\"client_secret\"]\n",
    "            }\n",
    "\n",
    "# Creates the connection to lightspeed, and returns a connection object with useful properties\n",
    "lsr = connection(store_data, credentials)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dealing with Pagination\n",
    "\n",
    "Lightspeed limits records returned to 100, so we need to page through the data and build an entire list of what we want. In this, we are calling the API to get a first set of 100 records, and then we use the data that is in the *@attributes* to get the total count of items, and then loop through to get all the items. We want to build a list of resources that we can .extend as we go, so we set up all_resources as a list.\n",
    "For educational purposes, this example ignores the rate limiting and any errors. Keep scrolling down to see examples with more handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going to try to redo this to be universal, but for now, using the resource variable as the name of the API endpoint\n",
    "resource = 'Category' #This is the name of the access point\n",
    "\n",
    "# Start at the beginning offset, and set the limit to Lightspeeds max of 100 records\n",
    "current_offset = 0\n",
    "current_limit = 100\n",
    "\n",
    "# Get the first chunk of data\n",
    "querystring = {'offset':current_offset, 'limit':current_limit}\n",
    "lightspeed_api = requests.get(lsr.api_url + resource + '.json', params=querystring, headers=lsr.headers)\n",
    "all_data = lightspeed_api.json()\n",
    "\n",
    "# Lightspeed API always returns two top level results - the @attributes which includes count, offset, and limit, and a second block that actually has the thing from the API. \n",
    "attributes = all_data['@attributes']\n",
    "all_resources = []\n",
    "all_resources = all_data[resource]\n",
    "\n",
    "# We can get the total number of things that are returned from the [@attributes][count]\n",
    "total_amount = int(all_data['@attributes']['count']) # We need to use these as integers so we can loop, so convert them\n",
    "current_offset = int(all_data['@attributes']['offset']) + int(all_data['@attributes']['limit'])\n",
    "current_limit = int(all_data['@attributes']['limit'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Looping\n",
    "Now that we have the first bit, we can look through it. We use the all_resources list we created above and .extend it to add all the records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "while total_amount > current_offset:\n",
    "    querystring = {'offset':current_offset, 'limit':current_limit}\n",
    "    all_data = requests.get(lsr.api_url + resource + '.json', params=querystring, headers=lsr.headers).json()\n",
    "    all_resources.extend(all_data[resource])\n",
    "    current_offset = current_offset + current_limit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dealing with the Rate Limit\n",
    "The header of the response contains information we need on the drip rate and bucket level. We can take a look at what is in the header, and we can get some variables ready to use in managing it. In this example, we are repeating everything from the example above, but modifying it so that it works with rate limiting. And again, I wrote this mostly as a way to figure out how it works, so it may look janky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": "2020-01-28 12:51:06,705 - DEBUG - Starting new HTTPS connection (1): api.lightspeedapp.com:443\n2020-01-28 12:51:07,020 - DEBUG - https://api.lightspeedapp.com:443 \"GET /API/Account/190211/Category.json?offset=0&limit=100 HTTP/1.1\" 200 3074\n2020-01-28 12:51:07,031 - DEBUG - Request Status Code: 200\n2020-01-28 12:51:07,032 - DEBUG - {'Date': 'Tue, 28 Jan 2020 17:51:07 GMT', 'Content-Type': 'application/json', 'Content-Length': '3074', 'Connection': 'keep-alive', 'Set-Cookie': '__cfduid=ddc8230b048e55ea8ca5efecae5c395d61580233867; expires=Thu, 27-Feb-20 17:51:07 GMT; path=/; domain=.lightspeedapp.com; HttpOnly; SameSite=Lax; Secure', 'x-frame-options': 'SAMEORIGIN', 'X-XSS-Protection': '1; mode=block', 'X-Content-Type-Options': 'nosniff', 'X-LS-Acct-Id': '190211', 'X-LS-OAuth-Client-Id': '71082', 'X-LS-API-Bucket-Level': '1/60', 'X-LS-Shard-Id': '23', 'X-LS-API-Drip-Rate': '1', 'X-LS-Master-System': 'false', 'X-LS-Master-Account': 'false', 'X-LS-Master-Catalog': 'false', 'Content-Encoding': 'gzip', 'Vary': 'Accept-Encoding', 'CF-Cache-Status': 'DYNAMIC', 'Expect-CT': 'max-age=604800, report-uri=\"https://report-uri.cloudflare.com/cdn-cgi/beacon/expect-ct\"', 'Server': 'cloudflare', 'CF-RAY': '55c4d0083c7f5e5c-TPA'}\n2020-01-28 12:51:07,033 - DEBUG - Bucket is at 1.0 with a size of 60.0 and a current drip rate of 1.0\n"
    }
   ],
   "source": [
    "# Going to try to redo this to be universal, but for now, using the resource variable as the name of the API endpoint\n",
    "resource = 'Category' #This is the name of the access point\n",
    "\n",
    "# Start at the beginning offset, and set the limit to Lightspeeds max of 100 records\n",
    "current_offset = 0\n",
    "current_limit = 100\n",
    "querystring = {'offset':current_offset, 'limit':current_limit}\n",
    "\n",
    "# Hold the whole content of the request object in the lightspeed_api variable.\n",
    "# TODO Really any time we create a request, we need to be managing a bunch of error handling.\n",
    "lightspeed_api = requests.get(lsr.api_url + resource + '.json', params=querystring, headers=lsr.headers)\n",
    "logging.debug(f\"Request Status Code: {lightspeed_api.status_code}\")\n",
    "# And hold just the json returned in all_data\n",
    "all_data = lightspeed_api.json()\n",
    "\n",
    "#Take a look at the header, and get some variables we can use\n",
    "logging.debug(lightspeed_api.headers)\n",
    "api_drip_rate = float(lightspeed_api.headers['X-LS-API-Drip-Rate'])\n",
    "# Since the bucket level comes back as a fraction, we pull it appart to get the pieces we need\n",
    "api_bucket_level, api_bucket_size = [(float(x)) for x in lightspeed_api.headers['X-LS-API-Bucket-Level'].split('/')]\n",
    "\n",
    "logging.debug(f\"Bucket is at {api_bucket_level} with a size of {api_bucket_size} and a current drip rate of {api_drip_rate}\")\n",
    "\n",
    "# Lightspeed API always returns two top level results in the json - the @attributes which includes count, offset, and limit, \n",
    "# and a second block that actually has the thing from the API. \n",
    "attributes = all_data['@attributes']\n",
    "all_resources = []\n",
    "all_resources = all_data[resource]\n",
    "\n",
    "# We can get the total number of things that are returned from the [@attributes][count]\n",
    "total_amount = int(all_data['@attributes']['count']) # We need to use these as integers so we can loop, so convert them\n",
    "current_offset = int(all_data['@attributes']['offset']) + int(all_data['@attributes']['limit'])\n",
    "current_limit = int(all_data['@attributes']['limit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "while total_amount > current_offset:\n",
    "    querystring = {'offset':current_offset, 'limit':current_limit}\n",
    "    all_data = requests.get(lsr.api_url + resource + '.json', params=querystring, headers=lsr.headers).json()\n",
    "    all_resources.extend(all_data[resource])\n",
    "    current_offset = current_offset + current_limit"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Write it out\n",
    "\n",
    "We can write out the results to a pandas data frame and then to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame(all_resources)\n",
    "# print(df)\n",
    "# df.to_csv(lsr.save_path+resource+\"_export.csv\")"
   ]
  }
 ]
}